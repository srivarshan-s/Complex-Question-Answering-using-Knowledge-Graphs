{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kwQnA'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_39158/4141489595.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkwQnA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exportPairs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexportToJSON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkwQnA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getentitypair\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGetEntity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkwQnA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGraphEnt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kwQnA'"
     ]
    }
   ],
   "source": [
    "import getopt\n",
    "import sys\n",
    "import json\n",
    "import pandas\n",
    "import re\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import inflect\n",
    "\n",
    "from kwQnA._complex import ComplexFunc\n",
    "from kwQnA._resolvedep import change_nouns\n",
    "from kwQnA._getentitypair import GetEntity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class exportToJSON:\n",
    "\n",
    "    def __init__(self):\n",
    "        super(exportToJSON, self).__init__()\n",
    "\n",
    "    def dumpdata(self, pairs):\n",
    "        \n",
    "        my_data = pairs.to_json('database.json', orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class exportToCSV:\n",
    "\n",
    "    def __init__(self):\n",
    "        super(exportToJSON, self).__init__()\n",
    "\n",
    "    def dumpdata(self, pairs):\n",
    "        df = pairs.to_csv(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetEntity:\n",
    "\n",
    "    def __init__(self):\n",
    "        super(GetEntity, self).__init__()\n",
    "        self.complex = ComplexFunc()\n",
    "        self.nlp = spacy.load('en_core_web_sm')\n",
    "        self.change = change_nouns()\n",
    "\n",
    "    def preprocess_text(self, input_file):\n",
    "        text_strip = [text.strip() for text in input_file]\n",
    "        preprocessed_text = [text for text in text_strip if text not in ('', ' ')]\n",
    "        text = \" \".join(preprocessed_text)\n",
    "        text = self.change.resolved(text)\n",
    "        text = self.nlp(text)\n",
    "        return text\n",
    "\n",
    "    def get_entity(self, text):\n",
    "        ent_pairs, final_entity_pairs = [],[]\n",
    "        sentences = [one_sentence.text.strip() for one_sentence in text.sents]\n",
    "\n",
    "        for one_sentence in sentences:\n",
    "            final_entity_pairs = []\n",
    "            one_sentence = self.nlp(one_sentence)\n",
    "\n",
    "            dep = [token.dep_ for token in one_sentence]\n",
    "\n",
    "            normal_sent_ = self.complex.normal_sent(one_sentence)\n",
    "\n",
    "            if normal_sent_:\n",
    "                for pair in normal_sent_:\n",
    "                    ent_pairs.append(pair)\n",
    "\n",
    "                pairs = pd.DataFrame(ent_pairs, columns=['source', 'relation', 'aux_relation', 'target', 'time', 'place'])\n",
    "                number_of_ent_pairs = str(len(ent_pairs))\n",
    "\n",
    "                final_entity_pairs.append(pairs)\n",
    "\n",
    "        if final_entity_pairs:\n",
    "            return final_entity_pairs, number_of_ent_pairs    \n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphEnt:\n",
    "\n",
    "    def __init__(self):\n",
    "        super(GraphEnt, self).__init__()\n",
    "        self.x = GetEntity()\n",
    "\n",
    "    def createGraph(self, dataEntities):\n",
    "        entity_list = dataEntities.values.tolist()\n",
    "        source, relations, target = [],[],[]\n",
    "\n",
    "        for i in entity_list:\n",
    "            source.append(i[0])\n",
    "            relations.append(i[1])\n",
    "            target.append(i[3])\n",
    "\n",
    "\n",
    "        kg_df = pd.DataFrame({'source':source, 'target':target, 'edge':relations})\n",
    "        G=nx.from_pandas_edgelist(kg_df, \"source\", \"target\", edge_attr=True, create_using=nx.MultiDiGraph())\n",
    "\n",
    "        plt.figure(figsize=(12,12))\n",
    "        pos = nx.spring_layout(G, k = 0.5)\n",
    "        ff =nx.draw(G, with_labels=True, node_color='skyblue', node_size=1500, edge_cmap=plt.cm.Blues, pos = pos)\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionAnswer:\n",
    "\n",
    "    def __init__(self):\n",
    "        super(QuestionAnswer, self).__init__()\n",
    "        self.complex = ComplexFunc()\n",
    "        self.nlp = spacy.load('en_core_web_sm')\n",
    "        self.p = inflect.engine()\n",
    "\n",
    "    def findanswer(self, question, c):\n",
    "        p = self.complex.question_pairs(question)\n",
    "\n",
    "        if p == [] or p is None:\n",
    "            return \"Not Applicable\"\n",
    "\n",
    "        pair = p[0]\n",
    "\n",
    "        f = open(\"database.json\",\"r\", encoding=\"utf8\")\n",
    "        listData = f.readlines()\n",
    "\n",
    "        relQ = []\n",
    "        loaded = json.loads(listData[0])\n",
    "        relationQ = self.nlp(pair[1])\n",
    "\n",
    "\n",
    "        for i in relationQ:\n",
    "            relationQ = i.lemma_\n",
    "            relQ.append(relationQ)\n",
    "\n",
    "        objectQ = pair[3]\n",
    "        subList = []\n",
    "        timeQ = str(pair[4]).lower()\n",
    "        placeQ = str(pair[5]).lower()\n",
    "\n",
    "        relationQ = \" \".join(relQ)\n",
    "\n",
    "        if pair[0] in ('who'):\n",
    "\n",
    "            for i in loaded:\n",
    "                relationS = [relation for relation in self.nlp(loaded[str(i)][\"relation\"])]\n",
    "                relationSSS = \" \".join([relation.lemma_ for relation in self.nlp(loaded[str(i)][\"relation\"])])\n",
    "\n",
    "                relationS = [i.lemma_ for i in relationS]\n",
    "                relationS = relationS[0]\n",
    "\n",
    "                if relationS == relationQ:\n",
    "                    objectS = loaded[str(i)][\"target\"]\n",
    "                    objectS = re.sub('-', ' ', objectS)\n",
    "                    objectQ = re.sub('-', ' ', objectQ)\n",
    "\n",
    "                    if self.p.singular_noun(objectS):\n",
    "                        objectS = self.p.singular_noun(objectS)\n",
    "                    if self.p.singular_noun(objectQ):\n",
    "                        objectQ = self.p.singular_noun(objectQ)\n",
    "\n",
    "                    if objectS == objectQ:\n",
    "                        if str(pair[4]) != \"\":\n",
    "                            timeS = [str(loaded[str(i)][\"time\"]).lower()]\n",
    "                            # print(timeQ, timeS)\n",
    "                            if timeQ in timeS:\n",
    "                                answer_subj = loaded[str(i)][\"source\"]\n",
    "                                subList.append(answer_subj)\n",
    "                        else:\n",
    "                            answer_subj = loaded[str(i)][\"source\"]\n",
    "                            subList.append(answer_subj)\n",
    "                elif str(relationSSS) == str(relationQ):\n",
    "                    objectS = loaded[str(i)][\"target\"]\n",
    "                    objectS = re.sub('-', ' ', objectS)\n",
    "\n",
    "                    if objectS == objectQ:\n",
    "                        if str(pair[4]) != \"\":\n",
    "                            timeS = [str(loaded[str(i)][\"time\"]).lower()]\n",
    "                            if timeQ in timeS:\n",
    "                                answer_subj = loaded[str(i)][\"source\"]\n",
    "                                subList.append(answer_subj)\n",
    "                        else:\n",
    "                            answer_subj = loaded[str(i)][\"source\"]\n",
    "                            subList.append(answer_subj)\n",
    "\n",
    "\n",
    "            answer_subj = \",\".join(subList)\n",
    "            if answer_subj == \"\":\n",
    "                return \"None\"\n",
    "            return answer_subj\n",
    "\n",
    "        elif pair[3] in ['what']:\n",
    "            subjectQ = pair[0]\n",
    "            subList = []\n",
    "            for i in loaded:\n",
    "                subjectS = loaded[str(i)][\"source\"]\n",
    "                if subjectQ == subjectS:\n",
    "                    relationS = [relation for relation in self.nlp(loaded[str(i)][\"relation\"])]\n",
    "                    relationS = [i.lemma_ for i in relationS]\n",
    "                    if len(relationS) > 1:\n",
    "                        relationS = \" \".join(relationS)\n",
    "                    else:\n",
    "                        relationS = relationS[0]\n",
    "                    if relationQ == relationS:\n",
    "                        if str(pair[5]) != \"\":\n",
    "                            placeS = [str(place).lower() for place in self.nlp(loaded[str(i)][\"place\"])]\n",
    "                            if placeQ in placeS:\n",
    "                                if str(pair[4]) != \"\":\n",
    "                                    timeS = [str(time).lower() for time in self.nlp(loaded[str(i)][\"time\"])]\n",
    "                                    if timeQ in timeS:\n",
    "                                        answer_subj = loaded[str(i)][\"target\"]\n",
    "                                        subList.append(answer_subj)\n",
    "                                else:\n",
    "                                    answer_subj = loaded[str(i)][\"target\"]\n",
    "                                    subList.append(answer_subj)\n",
    "                        else:\n",
    "                            if str(pair[4]) != \"\":\n",
    "                                timeS = [str(time).lower() for time in self.nlp(loaded[str(i)][\"time\"])]\n",
    "                                if timeQ in timeS:\n",
    "                                    answer_subj = loaded[str(i)][\"target\"]\n",
    "                                    subList.append(answer_subj)\n",
    "                            else:\n",
    "                                answer_subj = loaded[str(i)][\"target\"]\n",
    "                                subList.append(answer_subj)\n",
    "\n",
    "            answer_obj = \",\".join(subList)\n",
    "            if answer_obj == \"\":\n",
    "                return \"None\"\n",
    "            return answer_obj\n",
    "\n",
    "        elif pair[4] in ['when']:\n",
    "            subjectQ = pair[0]\n",
    "            for i in loaded:\n",
    "                subjectS = loaded[str(i)][\"source\"]\n",
    "                if subjectQ == subjectS:\n",
    "                    relationS = [relation for relation in self.nlp(loaded[str(i)][\"relation\"])]\n",
    "                    relationS = [i.lemma_ for i in relationS]\n",
    "                    relBuffer = relationS\n",
    "\n",
    "                    if len(relBuffer) < 2:\n",
    "                        relationS = relBuffer[0]\n",
    "                    else:\n",
    "                        if str(relBuffer[1]).lower() == 'to':\n",
    "                            relationS = \" \".join(relationS)\n",
    "                        else:\n",
    "                            relationS = relationS[0]\n",
    "                            extraIN = relBuffer[1].lower()\n",
    "\n",
    "                    if relationQ == relationS:\n",
    "                        if str(pair[5]) != \"\":\n",
    "                            placeS = [str(place).lower() for place in self.nlp(loaded[str(i)][\"place\"])]\n",
    "                            if placeQ in placeS:\n",
    "                                if loaded[str(i)][\"time\"] != '':\n",
    "                                    answer_obj = loaded[str(i)][\"time\"]\n",
    "                                    return answer_obj\n",
    "                                return None\n",
    "                        else:\n",
    "                            if loaded[str(i)][\"time\"] != '':\n",
    "                                answer_obj = loaded[str(i)][\"time\"]\n",
    "                                return answer_obj\n",
    "                            return None\n",
    "\n",
    "        elif pair[5] in ['where']:\n",
    "            subjectQ = pair[0]\n",
    "            for i in loaded:\n",
    "                subjectS = loaded[str(i)][\"source\"]\n",
    "                if subjectQ == subjectS:\n",
    "                    relationS = [relation for relation in self.nlp(loaded[str(i)][\"relation\"])]\n",
    "                    relationS = [i.lemma_ for i in relationS]\n",
    "                    relationS = relationS[0]\n",
    "\n",
    "                    if relationQ == relationS:\n",
    "                        if str(pair[4]) != \"\":\n",
    "                            timeS = [str(time).lower() for time in self.nlp(loaded[str(i)][\"time\"])]\n",
    "                            if timeQ in timeS:\n",
    "                                answer_obj = loaded[str(i)][\"place\"]\n",
    "                                if answer_obj in (\" \",\"\"):\n",
    "                                    if int(i)<int(len(loaded)-1):\n",
    "                                        pass\n",
    "                                    return None\n",
    "                                return answer_obj\n",
    "                            return None\n",
    "                        \n",
    "                        answer_obj = loaded[str(i)][\"place\"]\n",
    "                        if answer_obj in (\" \",\"\"):\n",
    "                            if int(i)<int(len(loaded)-1):\n",
    "                                pass\n",
    "                            return None\n",
    "                        return answer_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexFunc:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.ent_pairs = list()\n",
    "        self.nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "    def get_time_place_from_sent(self,sentence):\n",
    "        xdate =[]\n",
    "        xplace =[]\n",
    "        for i in sentence.ents:\n",
    "            if i.label_ in ('DATE'):\n",
    "                xdate.append(str(i))\n",
    "\n",
    "            if i.label_ in ('GPE'):\n",
    "                xplace.append(str(i))\n",
    "\n",
    "        return xdate, xplace\n",
    "\n",
    "    def find_obj(self, sentence, place, time):\n",
    "        object_list = []\n",
    "\n",
    "        for word in sentence:\n",
    "            if word.dep_ in ('obj', 'dobj', 'pobj'):\n",
    "                buffer_obj = word\n",
    "\n",
    "                if str(word) in place and word.nbor(-1).dep_ in ('prep') and str(word.nbor(-1)) == \"of\":\n",
    "                    pass\n",
    "                else:\n",
    "                    if str(word) not in time and str(word) not in place:\n",
    "                        for child in word.subtree:\n",
    "                            if child.dep_ in ('conj', 'dobj', 'pobj', 'obj') and (str(child) not in time) and (str(child) not in place):\n",
    "                                if [i for i in child.lefts]:\n",
    "                                    if child.nbor(-1).dep_ in ('nummod') and child.dep_ in ('dobj', 'obj','pobj'):\n",
    "                                        child = str(child.nbor(-1)) + \" \" + str(child)\n",
    "                                        object_list.append(str(child))\n",
    "\n",
    "                                    elif child.nbor(-1).dep_ in ('punct'):\n",
    "                                        if child.nbor(-2).dep_ in ('compound'):\n",
    "                                            child = str(child.nbor(-2)) + str(child.nbor(-1)) + str(child)\n",
    "                                            object_list.append(str(child))\n",
    "                                        elif child.nbor(-2).dep_ in ('amod'):\n",
    "                                            child = str(child.nbor(-2)) + str(child.nbor(-1)) + str(child)\n",
    "                                            object_list.append(str(child))\n",
    "\n",
    "                                    elif child.nbor(-1).dep_ in ('compound'):\n",
    "                                        child_with_comp = \"\"\n",
    "                                        for i in child.subtree:\n",
    "                                            if i.dep_ in ('compound', 'nummod','quantmod'):\n",
    "                                                if child_with_comp == \"\":\n",
    "                                                    child_with_comp = str(i)\n",
    "                                                else:\n",
    "                                                    child_with_comp = child_with_comp +\" \"+ str(i)\n",
    "                                            elif i.dep_ in ('cc'):\n",
    "                                                break\n",
    "                                        child = child_with_comp + \" \" + str(child)\n",
    "                                        # ice cream\n",
    "                                        object_list.append(str(child))\n",
    "\n",
    "                                    elif child.nbor(-1).dep_ in ('det'):\n",
    "                                        # The Taj Mahal\n",
    "                                        object_list.append(str(child))\n",
    "\n",
    "                                elif [i for i in child.rights]:\n",
    "                                    if str(child.text) not in object_list:\n",
    "                                        object_list.append(str(child.text))\n",
    "\n",
    "                                    for a in child.children:\n",
    "                                        if a.dep_ in ('conj'):\n",
    "                                            if a.nbor(-1).dep_ in ('punct'):\n",
    "                                                pass\n",
    "                                            else:\n",
    "                                                object_list.extend( [ str(a.text) ] )\n",
    "\n",
    "                                else:\n",
    "                                    # icecream\n",
    "                                    if str(child) not in object_list:\n",
    "                                        object_list.append(str(child))\n",
    "\n",
    "                    elif str(word) in place and str(word.nbor(-1)) != \"of\":\n",
    "                        if object_list == []:\n",
    "                            object_list.append(str(word))\n",
    "                        else:\n",
    "                            pass\n",
    "                    else:\n",
    "                        if str(word) in time and object_list == []:\n",
    "                            object_list.append(str(word))\n",
    "\n",
    "        return object_list, buffer_obj\n",
    "\n",
    "    def find_subj(self, sentence):\n",
    "        subject_list = []\n",
    "        dep_word = [word.dep_ for word in sentence]\n",
    "        word_dep_count_subj = [dep_word.index(word) for word in dep_word if word in ('nsubj', 'subj', 'nsubjpass')]\n",
    "        if word_dep_count_subj:\n",
    "            word_dep_count_subj = word_dep_count_subj[0] + 1\n",
    "        else:\n",
    "            word_dep_count_subj = 1\n",
    "\n",
    "        subject_final = \"\"\n",
    "        for word in sentence:\n",
    "            if word_dep_count_subj > 0:\n",
    "                if word.dep_ in ('compound') or word.dep_ in ('nmod') or word.dep_ in ('amod') or word.dep_ in ('poss') or word.dep_ in ('case') or word.dep_ in ('nummod'):\n",
    "                    if subject_final == \"\":\n",
    "                        subject_final = str(word)\n",
    "                        word_dep_count_subj = word_dep_count_subj - 1\n",
    "                    elif word.dep_ in ('case'):\n",
    "                        subject_final = subject_final+ \"\" +str(word)\n",
    "                        word_dep_count_subj = word_dep_count_subj - 1\n",
    "                    else:\n",
    "                        subject_final = subject_final+ \" \" +str(word)\n",
    "                        word_dep_count_subj = word_dep_count_subj - 1\n",
    "                elif word.dep_ in ('nsubj', 'subj', 'nsubjpass'):\n",
    "                    if subject_final == \"\":\n",
    "                        subject_final = str(word)\n",
    "                        subject_list.extend([str(a.text) for a in word.subtree if a.dep_ in ('conj')])\n",
    "                        word_dep_count_subj = word_dep_count_subj - 1\n",
    "                        break\n",
    "                    else:\n",
    "                        subject_final = subject_final+\" \"+str(word)\n",
    "                        subject_list.extend([str(a.text) for a in word.subtree if a.dep_ in ('conj')])\n",
    "                        word_dep_count_subj = word_dep_count_subj - 1\n",
    "                        break\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "        subject_list.append(subject_final)\n",
    "        return subject_list\n",
    "\n",
    "    def find_relation(self, buffer_obj):\n",
    "        aux_relation = \"\"\n",
    "        relation = [w for w in buffer_obj.ancestors if w.dep_ =='ROOT']\n",
    "\n",
    "        if relation:\n",
    "            relation = relation[0]\n",
    "            sp_relation = relation\n",
    "            if relation.nbor(1).pos_ in ('VERB'):\n",
    "                if relation.nbor(2).dep_ in ('xcomp'):\n",
    "                    relation = ' '.join((str(relation), str(relation.nbor(1)), str(relation.nbor(2))))\n",
    "                else:\n",
    "                    relation = str(relation)\n",
    "                    if str(sp_relation.nbor(2)) != 'and':\n",
    "                        if sp_relation.nbor(1).dep_ in ('xcomp'):\n",
    "                            aux_relation = str(sp_relation.nbor(1))\n",
    "                        else:\n",
    "                            aux_relation = str(sp_relation.nbor(2))\n",
    "            elif relation.nbor(1).pos_ in ('ADP', 'PART') and relation.nbor(1).dep_ in ('aux') and str(relation.nbor(1)) == 'to':\n",
    "                relation = \" \".join((str(relation), str(relation.nbor(1))))\n",
    "                if str(sp_relation.nbor(2)) != 'and':\n",
    "                    aux_relation = str(sp_relation.nbor(2))\n",
    "            elif relation.nbor(1).dep_ in ('prep') and str(relation.nbor(1)) == 'to' and (relation.nbor(1)).dep_ not in ('obj','dobj','pobj','det'):\n",
    "                relation = \" \".join((str(relation), str(relation.nbor(1))))\n",
    "            else:\n",
    "                relation = str(relation)\n",
    "        else:\n",
    "            relation = 'unknown'\n",
    "\n",
    "        return relation, aux_relation\n",
    "\n",
    "    def normal_sent(self, sentence):\n",
    "        time, place = self.get_time_place_from_sent(sentence)\n",
    "\n",
    "        subject_list, object_list = [], []\n",
    "\n",
    "        aux_relation, child_with_comp = \"\", \"\"\n",
    "\n",
    "        subject_list = self.find_subj(sentence)\n",
    "        object_list, buffer_obj = self.find_obj(sentence, place, time)\n",
    "        relation, aux_relation = self.find_relation(buffer_obj)\n",
    "\n",
    "        self.ent_pairs = []\n",
    "\n",
    "        if time:\n",
    "            time = time[0]\n",
    "        else:\n",
    "            time = \"\"\n",
    "\n",
    "        if place:\n",
    "            place = place[0]\n",
    "        else:\n",
    "            place = \"\"\n",
    "\n",
    "        pa, pb=[], []\n",
    "        for m in subject_list:\n",
    "            pa.append([m])\n",
    "\n",
    "        for n in object_list:\n",
    "            pb.append([n])\n",
    "\n",
    "\n",
    "        for m in range(0, len(pa)):\n",
    "            for n in range(0, len(pb)):\n",
    "                self.ent_pairs.append([str(pa[m][0]).lower(), str(relation).lower(),str(aux_relation).lower(), str(pb[n][0]).lower(), str(time), str(place)])\n",
    "\n",
    "        return self.ent_pairs\n",
    "\n",
    "    def question_pairs(self, question__):\n",
    "\n",
    "        questionNLPed = self.nlp(question__)\n",
    "        maybe_object = ([i for i in questionNLPed if i.dep_ in ('obj', 'pobj', 'dobj')])\n",
    "        maybe_place, maybe_time = [], []\n",
    "        aux_relation = \"\"\n",
    "        maybe_time, maybe_place = self.get_time_place_from_sent(questionNLPed)\n",
    "        object_list = []\n",
    "\n",
    "        for obj in questionNLPed:\n",
    "            objectNEW = obj\n",
    "\n",
    "            if obj.dep_ in ('obj', 'dobj', 'pobj', 'xcomp') and str(obj).lower() != \"what\":\n",
    "                buffer_obj = obj\n",
    "\n",
    "                if obj.dep_ in ('xcomp') and obj.nbor(-1).dep_ in ('aux') and obj.nbor(-2).dep_ in ('ROOT'):\n",
    "                    continue\n",
    "\n",
    "                if str(obj) in maybe_place and obj.nbor(-1).dep_ in ('prep') and str(obj.nbor(-1)) == \"of\":\n",
    "                    pass\n",
    "                else:\n",
    "                    if str(obj) not in maybe_time and str(obj) not in maybe_place:\n",
    "                        for child in obj.subtree:\n",
    "                            if child.dep_ in ('conj', 'dobj', 'pobj', 'obj'):\n",
    "                                if [i for i in child.lefts]:\n",
    "                                    if child.nbor(-1).dep_ in ('punct') and child.nbor(-2).dep_ in ('compound'):\n",
    "                                        child = str(child.nbor(-2)) + str(child.nbor(-1)) + str(child)\n",
    "                                        object_list.append(str(child))\n",
    "\n",
    "                                    elif child.nbor(-1).dep_ in ('compound'):\n",
    "                                        child_with_comp = \"\"\n",
    "                                        for i in child.subtree:\n",
    "                                            if i.dep_ in ('compound', 'nummod','quantmod'):\n",
    "                                                if child_with_comp == \"\":\n",
    "                                                    child_with_comp = str(i)\n",
    "                                                else:\n",
    "                                                    child_with_comp = child_with_comp +\" \"+ str(i)\n",
    "                                            elif i.dep_ in ('cc'):\n",
    "                                                break\n",
    "                                        child = child_with_comp + \" \" + str(child)\n",
    "\n",
    "                                        object_list.append(str(child))\n",
    "\n",
    "                                    elif child.nbor(-1).dep_ in ('det'):\n",
    "                                        object_list.append(str(child))\n",
    "\n",
    "                                elif [i for i in child.rights]:\n",
    "                                    if str(child.text) not in object_list:\n",
    "                                        object_list.append(str(child.text))\n",
    "\n",
    "                                    for a in child.children:\n",
    "                                        if a.dep_ in ('conj'):\n",
    "                                            if a.nbor(-1).dep_ in ('punct'):\n",
    "                                                pass\n",
    "                                            else:\n",
    "                                                object_list.extend( [ str(a.text) ] )\n",
    "\n",
    "                                else:\n",
    "                                    if str(child) not in object_list:\n",
    "                                        object_list.append(str(child))\n",
    "\n",
    "                            elif obj.dep_ in ('xcomp'):\n",
    "                                object_list.append(str(obj))\n",
    "\n",
    "                    elif str(obj) in maybe_place and str(obj.nbor(-1)) != \"of\":\n",
    "                        object_list.append(str(obj))\n",
    "                    else:\n",
    "                        if str(obj) in time and object_list == []:\n",
    "                            object_list.append(str(obj))\n",
    "\n",
    "\n",
    "                obj = object_list[-1]\n",
    "\n",
    "\n",
    "                relation = [w for w in objectNEW.ancestors if w.dep_ =='ROOT']\n",
    "                if relation:\n",
    "                    relation = relation[0]\n",
    "                    sp_relation = relation\n",
    "                    if relation.nbor(1).pos_ in ('ADP', 'PART', 'VERB'):\n",
    "                        if relation.nbor(2).dep_ in ('xcomp'):\n",
    "                            aux_relation = str(relation.nbor(2))\n",
    "                            relation = str(relation)+\" \"+str(relation.nbor(1))\n",
    "                        else:\n",
    "                            relation = str(relation)\n",
    "\n",
    "                    subject = [a for a in sp_relation.lefts if a.dep_ in ('subj', 'nsubj','nsubjpass')]\n",
    "                    if subject:\n",
    "                        subject = subject[0]\n",
    "                    else:\n",
    "                        subject = 'unknown'\n",
    "                else:\n",
    "                    relation = 'unknown'\n",
    "\n",
    "                self.ent_pairs = []\n",
    "\n",
    "                if maybe_time and maybe_place:\n",
    "                    self.ent_pairs.append([str(subject).lower(), str(relation).lower(),str(aux_relation).lower(), str(obj).lower(), str(maybe_time[0]).lower(), str(maybe_place[0]).lower()])\n",
    "                elif maybe_time:\n",
    "                    self.ent_pairs.append([str(subject).lower(), str(relation).lower(),str(aux_relation).lower(), str(obj).lower(), str(maybe_time[0]).lower(), str(\"\").lower()])\n",
    "                elif maybe_place:\n",
    "                    self.ent_pairs.append([str(subject).lower(), str(relation).lower(),str(aux_relation).lower(), str(obj).lower(), str(\"\").lower(), str(maybe_place[0]).lower()])\n",
    "                else:\n",
    "                    self.ent_pairs.append([str(subject).lower(), str(relation).lower(),str(aux_relation).lower(), str(obj).lower(), str(\"\").lower(), str(\"\").lower()])\n",
    "                return self.ent_pairs\n",
    "\n",
    "            elif str(obj).lower() == \"what\":\n",
    "                relation = [w for w in objectNEW.ancestors if w.dep_ =='ROOT']\n",
    "                if relation:\n",
    "                    relation = relation[0]\n",
    "                    sp_relation = relation\n",
    "                    if relation.nbor(1).pos_ in ('ADP', 'PART', 'VERB'):\n",
    "                        if relation.nbor(2).dep_ in ('xcomp'):\n",
    "                            aux_relation = str(relation.nbor(2))\n",
    "                            relation = str(relation)+\" \"+str(relation.nbor(1))\n",
    "                        else:\n",
    "                            relation = str(relation)\n",
    "\n",
    "                    subject = self.find_subj(questionNLPed)\n",
    "                    subject = subject[-1]\n",
    "\n",
    "                else:\n",
    "                    relation = 'unknown'\n",
    "\n",
    "                self.ent_pairs = []\n",
    "                if maybe_time and maybe_place:\n",
    "                    self.ent_pairs.append([str(subject).lower(), str(relation).lower(),str(aux_relation).lower(), str(obj).lower(), str(maybe_time[0]).lower(), str(maybe_place[0]).lower()])\n",
    "                elif maybe_time:\n",
    "                    self.ent_pairs.append([str(subject).lower(), str(relation).lower(),str(aux_relation).lower(), str(obj).lower(), str(maybe_time[0]).lower(), str(\"\").lower()])\n",
    "                elif maybe_place:\n",
    "                    self.ent_pairs.append([str(subject).lower(), str(relation).lower(),str(aux_relation).lower(), str(obj).lower(), str(\"\").lower(), str(maybe_place[0]).lower()])\n",
    "                else:\n",
    "                    self.ent_pairs.append([str(subject).lower(), str(relation).lower(),str(aux_relation).lower(), str(obj).lower(), str(\"\").lower(), str(\"\").lower()])\n",
    "                return self.ent_pairs\n",
    "\n",
    "            elif obj.dep_ in ('advmod'):\n",
    "                if str(obj).lower() == 'where':\n",
    "                    relation = [w for w in obj.ancestors if w.dep_ =='ROOT']\n",
    "                    if relation:\n",
    "                        relation = relation[0]\n",
    "                        sp_relation = relation\n",
    "                        if relation.nbor(1).pos_ in ('ADP', 'PART', 'VERB'):\n",
    "                            if relation.nbor(2).dep_ in ('xcomp'):\n",
    "                                aux_relation = str(relation.nbor(2))\n",
    "                                relation = str(relation)+\" \"+str(relation.nbor(1))\n",
    "                            else:\n",
    "                                relation = str(relation)\n",
    "\n",
    "\n",
    "                        subject = self.find_subj(questionNLPed)\n",
    "                        subject = subject[-1]\n",
    "\n",
    "                    else:\n",
    "                        relation = 'unknown'\n",
    "\n",
    "                    self.ent_pairs = []\n",
    "                    if maybe_object:\n",
    "                        if maybe_time and maybe_place:\n",
    "                            self.ent_pairs.append([str(subject).lower(), str(relation).lower(),str(aux_relation).lower(), str(maybe_object[-1]).lower(), str(maybe_time[0]).lower(), str(\"where\").lower()])\n",
    "                        elif maybe_time:\n",
    "                            self.ent_pairs.append([str(subject).lower(), str(relation).lower(),str(aux_relation).lower(), str(maybe_object[-1]).lower(), str(maybe_time[0]).lower(), str(\"where\").lower()])\n",
    "                        elif maybe_place:\n",
    "                            self.ent_pairs.append([str(subject).lower(), str(relation).lower(),str(aux_relation).lower(), str(maybe_object[-1]).lower(), str(\"\").lower(), str(\"where\").lower()])\n",
    "                        else:\n",
    "                            self.ent_pairs.append([str(subject).lower(), str(relation).lower(),str(aux_relation).lower(), str(maybe_object[-1]).lower(), str(\"\").lower(), str(\"where\").lower()])\n",
    "                    else:\n",
    "                        if maybe_time and maybe_place:\n",
    "                            self.ent_pairs.append([str(subject).lower(), str(relation).lower(),str(aux_relation).lower(), str(\"\").lower(), str(maybe_time[0]).lower(), str(\"where\").lower()])\n",
    "                        elif maybe_time:\n",
    "                            self.ent_pairs.append([str(subject).lower(), str(relation).lower(),str(aux_relation).lower(), str(\"\").lower(), str(maybe_time[0]).lower(), str(\"where\").lower()])\n",
    "                        elif maybe_place:\n",
    "                            self.ent_pairs.append([str(subject).lower(), str(relation).lower(),str(aux_relation).lower(), str(\"\").lower(), str(\"\").lower(), str(\"where\").lower()])\n",
    "                        else:\n",
    "                            self.ent_pairs.append([str(subject).lower(), str(relation).lower(),str(aux_relation).lower(), str(\"\").lower(), str(\"\").lower(), str(\"where\").lower()])\n",
    "\n",
    "\n",
    "                    return self.ent_pairs\n",
    "\n",
    "                elif str(obj).lower() == 'when':\n",
    "                    relation = [w for w in obj.ancestors if w.dep_ =='ROOT']\n",
    "                    if relation:\n",
    "                        relation = relation[0]\n",
    "                        sp_relation = relation\n",
    "                        if relation.nbor(1).pos_ in ('ADP', 'PART', 'VERB'):\n",
    "                            if relation.nbor(2).dep_ in ('xcomp'):\n",
    "                                relation = ' '.join((str(relation), str(relation.nbor(1)), str(relation.nbor(2))))\n",
    "                            else:\n",
    "                                relation = ' '.join((str(relation), str(relation.nbor(1))))\n",
    "\n",
    "                        for left_word in sp_relation.lefts:\n",
    "                            if left_word.dep_ in ('subj', 'nsubj','nsubjpass'):\n",
    "                                if [i for i in left_word.lefts]:\n",
    "                                    for left_of_left_word in left_word.lefts:\n",
    "                                        subject = str(left_of_left_word) + \" \" + str(left_word)\n",
    "                                else:\n",
    "                                    subject = str(left_word)\n",
    "                    else:\n",
    "                        relation = 'unknown'\n",
    "\n",
    "                    self.ent_pairs = []\n",
    "                    if maybe_object:\n",
    "                        if maybe_time and maybe_place:\n",
    "                            self.ent_pairs.append([str(subject).lower(), str(relation).lower(),str(aux_relation).lower(), str(maybe_object[-1]).lower(), str(\"when\").lower(), str(maybe_place[0]).lower()])\n",
    "                        elif maybe_time:\n",
    "                            self.ent_pairs.append([str(subject).lower(), str(relation).lower(),str(aux_relation).lower(), str(maybe_object[-1]).lower(), str(\"when\").lower(), str(\"\").lower()])\n",
    "                        elif maybe_place:\n",
    "                            self.ent_pairs.append([str(subject).lower(), str(relation).lower(),str(aux_relation).lower(), str(maybe_object[-1]).lower(), str(\"when\").lower(), str(maybe_place[0]).lower()])\n",
    "                        else:\n",
    "                            self.ent_pairs.append([str(subject).lower(), str(relation).lower(),str(aux_relation).lower(), str(maybe_object[-1]).lower(), str(\"when\").lower(), str(\"\").lower()])\n",
    "                    else:\n",
    "                        if maybe_time and maybe_place:\n",
    "                            self.ent_pairs.append([str(subject).lower(), str(relation).lower(),str(aux_relation).lower(), str(\"\").lower(), str(\"when\").lower(), str(maybe_place[0]).lower()])\n",
    "                        elif maybe_time:\n",
    "                            self.ent_pairs.append([str(subject).lower(), str(relation).lower(),str(aux_relation).lower(), str(\"\").lower(), str(\"when\").lower(), str(\"\").lower()])\n",
    "                        elif maybe_place:\n",
    "                            self.ent_pairs.append([str(subject).lower(), str(relation).lower(),str(aux_relation).lower(), str(\"\").lower(), str(\"when\").lower(), str(maybe_place[0]).lower()])\n",
    "                        else:\n",
    "                            self.ent_pairs.append([str(subject).lower(), str(relation).lower(),str(aux_relation).lower(), str(\"\").lower(), str(\"when\").lower(), str(\"\").lower()])\n",
    "\n",
    "                    return self.ent_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "778f36b5a4644f9c18d9e0a5c0a7c4f607e7129dbeea5d42f47e6a06957b0bbd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
